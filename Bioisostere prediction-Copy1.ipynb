{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45576404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = \"C:/Users/super/OneDrive - The University of Tokyo/Portfolio Research work with Korbtham/Project_Bioisostere_Prediction/TryProject1/Dataset/ci0c00290_si_002.txt\"\n",
    "data = pd.read_csv(path,sep='  ',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1183bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f58341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['1'] = [0 for i in range(0,2100)]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fab3d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "n,m = data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63a77c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n):\n",
    "    lis = data.iloc[i,0].split('\\t')\n",
    "    data.iloc[i,0] = lis[0]\n",
    "    data.iloc[i,1] = lis[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a79d802",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove[R]\n",
    "for i in range(n):\n",
    "    data.iloc[i,0] = data.iloc[i,0].replace('[R]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47239df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e8db27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach the row of substitutes data\n",
    "n,m = data.shape\n",
    "lis_sub = []\n",
    "for i in range(n):\n",
    "    if data.iloc[i,1] == '*':\n",
    "        lis_sub.append(data.iloc[i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2807e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lis_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b62d62a",
   "metadata": {},
   "source": [
    "Then we will pefrom fragment descriptors for each substitues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7829ce7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encod = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ec96e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encod.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0d244c",
   "metadata": {},
   "source": [
    "#https://www.blopig.com/blog/2022/06/how-to-turn-a-molecule-into-a-vector-of-physicochemical-descriptors-using-rdkit/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc559146",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will perform the molecular desciptors from smiles strucutre\n",
    "from rdkit import Chem\n",
    "from rdkit.ML.Descriptors.MoleculeDescriptors import MolecularDescriptorCalculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43748ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_string = 'CN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425c1c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "mol = Chem.MolFromSmiles(smiles_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89820f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_descriptors = ['BalabanJ', 'BertzCT', 'Chi0', 'Chi0n', 'Chi0v', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', 'Chi2v', 'Chi3n', 'Chi3v', 'Chi4n', 'Chi4v', 'EState_VSA1', 'EState_VSA10', 'EState_VSA11', 'EState_VSA2', 'EState_VSA3', 'EState_VSA4', 'EState_VSA5', 'EState_VSA6', 'EState_VSA7', 'EState_VSA8', 'EState_VSA9', 'ExactMolWt', 'FpDensityMorgan1', 'FpDensityMorgan2', 'FpDensityMorgan3', 'FractionCSP3', 'HallKierAlpha', 'HeavyAtomCount', 'HeavyAtomMolWt', 'Ipc', 'Kappa1', 'Kappa2', 'Kappa3', 'LabuteASA', 'MaxAbsEStateIndex', 'MaxAbsPartialCharge', 'MaxEStateIndex', 'MaxPartialCharge', 'MinAbsEStateIndex', 'MinAbsPartialCharge', 'MinEStateIndex', 'MinPartialCharge', 'MolLogP', 'MolMR', 'MolWt', 'NHOHCount', 'NOCount', 'NumAliphaticCarbocycles', 'NumAliphaticHeterocycles', 'NumAliphaticRings', 'NumAromaticCarbocycles', 'NumAromaticHeterocycles', 'NumAromaticRings', 'NumHAcceptors', 'NumHDonors', 'NumHeteroatoms', 'NumRadicalElectrons', 'NumRotatableBonds', 'NumSaturatedCarbocycles', 'NumSaturatedHeterocycles', 'NumSaturatedRings', 'NumValenceElectrons', 'PEOE_VSA1', 'PEOE_VSA10', 'PEOE_VSA11', 'PEOE_VSA12', 'PEOE_VSA13', 'PEOE_VSA14', 'PEOE_VSA2', 'PEOE_VSA3', 'PEOE_VSA4', 'PEOE_VSA5', 'PEOE_VSA6', 'PEOE_VSA7', 'PEOE_VSA8', 'PEOE_VSA9', 'RingCount', 'SMR_VSA1', 'SMR_VSA10', 'SMR_VSA2', 'SMR_VSA3', 'SMR_VSA4', 'SMR_VSA5', 'SMR_VSA6', 'SMR_VSA7', 'SMR_VSA8', 'SMR_VSA9', 'SlogP_VSA1', 'SlogP_VSA10', 'SlogP_VSA11', 'SlogP_VSA12', 'SlogP_VSA2', 'SlogP_VSA3', 'SlogP_VSA4', 'SlogP_VSA5', 'SlogP_VSA6', 'SlogP_VSA7', 'SlogP_VSA8', 'SlogP_VSA9', 'TPSA', 'VSA_EState1', 'VSA_EState10', 'VSA_EState2', 'VSA_EState3', 'VSA_EState4', 'VSA_EState5', 'VSA_EState6', 'VSA_EState7', 'VSA_EState8', 'VSA_EState9', 'fr_Al_COO', 'fr_Al_OH', 'fr_Al_OH_noTert', 'fr_ArN', 'fr_Ar_COO', 'fr_Ar_N', 'fr_Ar_NH', 'fr_Ar_OH', 'fr_COO', 'fr_COO2', 'fr_C_O', 'fr_C_O_noCOO', 'fr_C_S', 'fr_HOCCN', 'fr_Imine', 'fr_NH0', 'fr_NH1', 'fr_NH2', 'fr_N_O', 'fr_Ndealkylation1', 'fr_Ndealkylation2', 'fr_Nhpyrrole', 'fr_SH', 'fr_aldehyde', 'fr_alkyl_carbamate', 'fr_alkyl_halide', 'fr_allylic_oxid', 'fr_amide', 'fr_amidine', 'fr_aniline', 'fr_aryl_methyl', 'fr_azide', 'fr_azo', 'fr_barbitur', 'fr_benzene', 'fr_benzodiazepine', 'fr_bicyclic', 'fr_diazo', 'fr_dihydropyridine', 'fr_epoxide', 'fr_ester', 'fr_ether', 'fr_furan', 'fr_guanido', 'fr_halogen', 'fr_hdrzine', 'fr_hdrzone', 'fr_imidazole', 'fr_imide', 'fr_isocyan', 'fr_isothiocyan', 'fr_ketone', 'fr_ketone_Topliss', 'fr_lactam', 'fr_lactone', 'fr_methoxy', 'fr_morpholine', 'fr_nitrile', 'fr_nitro', 'fr_nitro_arom', 'fr_nitro_arom_nonortho', 'fr_nitroso', 'fr_oxazole', 'fr_oxime', 'fr_para_hydroxylation', 'fr_phenol', 'fr_phenol_noOrthoHbond', 'fr_phos_acid', 'fr_phos_ester', 'fr_piperdine', 'fr_piperzine', 'fr_priamide', 'fr_prisulfonamd', 'fr_pyridine', 'fr_quatN', 'fr_sulfide', 'fr_sulfonamd', 'fr_sulfone', 'fr_term_acetylene', 'fr_tetrazole', 'fr_thiazole', 'fr_thiocyan', 'fr_thiophene', 'fr_unbrch_alkane', 'fr_urea', 'qed']\n",
    "# create molecular descriptor calculator\n",
    "mol_descriptor_calculator = MolecularDescriptorCalculator(chosen_descriptors)\n",
    "# use molecular descriptor calculator on RDKit mol object\n",
    "list_of_descriptor_vals = list(mol_descriptor_calculator.CalcDescriptors(mol))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbf59e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will generate the dataset containing molecular desciptors and smile string \n",
    "# rename the column of data_encod\n",
    "data_encod.rename(columns = {0:'SMILES','1':'Count'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b325010",
   "metadata": {},
   "outputs": [],
   "source": [
    "for des in chosen_descriptors:\n",
    "    data_encod[des] = [0 for i in range(0,2100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958292ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,2100):\n",
    "    smile_string = data_encod.iloc[i,0]\n",
    "    mol = Chem.MolFromSmiles(smiles_string)\n",
    "    mol_descriptor_calculator = MolecularDescriptorCalculator(chosen_descriptors)\n",
    "    list_of_descriptor_vals = list(mol_descriptor_calculator.CalcDescriptors(mol)\n",
    "    data_encod.iloc[i,2:202] = list_of_descriptor_vals\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f5a02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,2100):\n",
    "    smiles_string = data_encod.iloc[i,0]\n",
    "    # convert SMILES string to RDKit mol object\n",
    "    mol = Chem.MolFromSmiles(smiles_string)\n",
    "    # choose 200 molecular descriptors\n",
    "    chosen_descriptors = ['BalabanJ', 'BertzCT', 'Chi0', 'Chi0n', 'Chi0v', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', 'Chi2v', 'Chi3n', 'Chi3v', 'Chi4n', 'Chi4v', 'EState_VSA1', 'EState_VSA10', 'EState_VSA11', 'EState_VSA2', 'EState_VSA3', 'EState_VSA4', 'EState_VSA5', 'EState_VSA6', 'EState_VSA7', 'EState_VSA8', 'EState_VSA9', 'ExactMolWt', 'FpDensityMorgan1', 'FpDensityMorgan2', 'FpDensityMorgan3', 'FractionCSP3', 'HallKierAlpha', 'HeavyAtomCount', 'HeavyAtomMolWt', 'Ipc', 'Kappa1', 'Kappa2', 'Kappa3', 'LabuteASA', 'MaxAbsEStateIndex', 'MaxAbsPartialCharge', 'MaxEStateIndex', 'MaxPartialCharge', 'MinAbsEStateIndex', 'MinAbsPartialCharge', 'MinEStateIndex', 'MinPartialCharge', 'MolLogP', 'MolMR', 'MolWt', 'NHOHCount', 'NOCount', 'NumAliphaticCarbocycles', 'NumAliphaticHeterocycles', 'NumAliphaticRings', 'NumAromaticCarbocycles', 'NumAromaticHeterocycles', 'NumAromaticRings', 'NumHAcceptors', 'NumHDonors', 'NumHeteroatoms', 'NumRadicalElectrons', 'NumRotatableBonds', 'NumSaturatedCarbocycles', 'NumSaturatedHeterocycles', 'NumSaturatedRings', 'NumValenceElectrons', 'PEOE_VSA1', 'PEOE_VSA10', 'PEOE_VSA11', 'PEOE_VSA12', 'PEOE_VSA13', 'PEOE_VSA14', 'PEOE_VSA2', 'PEOE_VSA3', 'PEOE_VSA4', 'PEOE_VSA5', 'PEOE_VSA6', 'PEOE_VSA7', 'PEOE_VSA8', 'PEOE_VSA9', 'RingCount', 'SMR_VSA1', 'SMR_VSA10', 'SMR_VSA2', 'SMR_VSA3', 'SMR_VSA4', 'SMR_VSA5', 'SMR_VSA6', 'SMR_VSA7', 'SMR_VSA8', 'SMR_VSA9', 'SlogP_VSA1', 'SlogP_VSA10', 'SlogP_VSA11', 'SlogP_VSA12', 'SlogP_VSA2', 'SlogP_VSA3', 'SlogP_VSA4', 'SlogP_VSA5', 'SlogP_VSA6', 'SlogP_VSA7', 'SlogP_VSA8', 'SlogP_VSA9', 'TPSA', 'VSA_EState1', 'VSA_EState10', 'VSA_EState2', 'VSA_EState3', 'VSA_EState4', 'VSA_EState5', 'VSA_EState6', 'VSA_EState7', 'VSA_EState8', 'VSA_EState9', 'fr_Al_COO', 'fr_Al_OH', 'fr_Al_OH_noTert', 'fr_ArN', 'fr_Ar_COO', 'fr_Ar_N', 'fr_Ar_NH', 'fr_Ar_OH', 'fr_COO', 'fr_COO2', 'fr_C_O', 'fr_C_O_noCOO', 'fr_C_S', 'fr_HOCCN', 'fr_Imine', 'fr_NH0', 'fr_NH1', 'fr_NH2', 'fr_N_O', 'fr_Ndealkylation1', 'fr_Ndealkylation2', 'fr_Nhpyrrole', 'fr_SH', 'fr_aldehyde', 'fr_alkyl_carbamate', 'fr_alkyl_halide', 'fr_allylic_oxid', 'fr_amide', 'fr_amidine', 'fr_aniline', 'fr_aryl_methyl', 'fr_azide', 'fr_azo', 'fr_barbitur', 'fr_benzene', 'fr_benzodiazepine', 'fr_bicyclic', 'fr_diazo', 'fr_dihydropyridine', 'fr_epoxide', 'fr_ester', 'fr_ether', 'fr_furan', 'fr_guanido', 'fr_halogen', 'fr_hdrzine', 'fr_hdrzone', 'fr_imidazole', 'fr_imide', 'fr_isocyan', 'fr_isothiocyan', 'fr_ketone', 'fr_ketone_Topliss', 'fr_lactam', 'fr_lactone', 'fr_methoxy', 'fr_morpholine', 'fr_nitrile', 'fr_nitro', 'fr_nitro_arom', 'fr_nitro_arom_nonortho', 'fr_nitroso', 'fr_oxazole', 'fr_oxime', 'fr_para_hydroxylation', 'fr_phenol', 'fr_phenol_noOrthoHbond', 'fr_phos_acid', 'fr_phos_ester', 'fr_piperdine', 'fr_piperzine', 'fr_priamide', 'fr_prisulfonamd', 'fr_pyridine', 'fr_quatN', 'fr_sulfide', 'fr_sulfonamd', 'fr_sulfone', 'fr_term_acetylene', 'fr_tetrazole', 'fr_thiazole', 'fr_thiocyan', 'fr_thiophene', 'fr_unbrch_alkane', 'fr_urea', 'qed']\n",
    "    # create molecular descriptor calculator\n",
    "    mol_descriptor_calculator = MolecularDescriptorCalculator(chosen_descriptors)\n",
    "    # use molecular descriptor calculator on RDKit mol object\n",
    "    list_of_descriptor_vals = list(mol_descriptor_calculator.CalcDescriptors(mol))\n",
    "    data_encod.iloc[i,2:202] = list_of_descriptor_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5acc5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a327e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save encoded data to csv file\n",
    "data_encod.to_csv('preprocess_descriptors_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68826b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "831d24c3",
   "metadata": {},
   "source": [
    "Since there are many descriptors(around 200 descriptors), so we need to perform dimension reduction used principal component analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f468a7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we need to perform standardized before principal analysis\n",
    "data_encod = data_encod[chosen_descriptors]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scalar = StandardScaler()\n",
    "data_scaled = pd.DataFrame(scalar.fit_transform(data_encod), columns=data_encod.columns)\n",
    "data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9020a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "data_pca = pd.DataFrame(pca.fit_transform(data_scaled))\n",
    "data_pca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54018175",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74ed8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_explained = pd.DataFrame(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b804aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_explained[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79e3a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# calculate cumulative sum of explained variances\n",
    "tot = sum(df_explained[0])\n",
    "var_exp = [(i / tot) for i in sorted(df_explained[0], reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "var_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32f91a4",
   "metadata": {},
   "source": [
    "Based on the PCA result, we see that the only first components capture almost 98.3% of the data. However, we will use two components for this model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1463f819",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['PCA1','PCA2']] = data_pca.iloc[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e0531b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cf6ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as an input X training data\n",
    "data.to_csv('X_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adc62ab",
   "metadata": {},
   "source": [
    "Perform multi-hot encoding on the dataset\n",
    "\n",
    "1) we will create the list for substitutes data\n",
    "\n",
    "2) we will create the list that contains all of analogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36589c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns = {0:'SMILES', '1':'Value'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf615d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the substitutes dataset \n",
    "sub = data[data['Value']=='*']\n",
    "lis_sub = list(sub['SMILES'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453dd016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The list contain all of analog\n",
    "lis_ana = []\n",
    "n,m = data.shape\n",
    "for i in range(n):\n",
    "    k = data.iloc[i,0]\n",
    "    if k not in lis_ana:\n",
    "        lis_ana.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd4bea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then we will generate multi-hor encoded array \n",
    "mult_encod = np.zeros((len(lis_sub),len(lis_ana)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbde0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lis_i = []\n",
    "for i in range(n):\n",
    "    if data.iloc[i,1] == '*':\n",
    "       lis_i.append(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57262ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data.iloc[1:22,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec46983",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "for i in range(2100):\n",
    "    if i%21 ==0:\n",
    "        print(i)\n",
    "        key = data.iloc[i,0]\n",
    "        lis = list(data.iloc[i+1:i+20,0])\n",
    "        dic[key] = lis\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9a1eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7fa423",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa7f7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then perform multi-hot encoding \n",
    "mult_encod = np.zeros((len(lis_sub),len(lis_ana)))\n",
    "for i in range(len(lis_sub)):\n",
    "    sub = lis_sub[i] # substitution sting \n",
    "    ana = dic[sub]   # analogous\n",
    "    for j in range(len(lis_ana)):\n",
    "        if lis_ana[j] in ana:\n",
    "            mult_encod[i][j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02e0473",
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_encod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d425cf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_encod_frame = pd.DataFrame(mult_encod,index=lis_sub,columns=lis_ana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4967b76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saved Y dataset\n",
    "mult_encod_frame.to_csv('Y_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab44a191",
   "metadata": {},
   "source": [
    "<b> Deep learning model </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99dba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69be98d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e398c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop('Value',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806c8787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select only compound in the list_sub\n",
    "p = [21*i for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0ecf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.iloc[p,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329e1588",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.iloc[:,1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445e6fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad7dac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = mult_encod_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8f2e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bc9e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to find appropriate deep learning neural network\n",
    "#How to perform the model for .....\n",
    "# How to perform leave-out one cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cfb538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "#create model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "model = Sequential()\n",
    "\n",
    "#get number of columns in training data\n",
    "ncx,ncy = Y_train.shape\n",
    "n_cols = X_train.shape[1]\n",
    "\n",
    "#add model layers\n",
    "model.add(Dense(10000, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(10000, activation='relu'))\n",
    "model.add(Dense(10000, activation='relu'))\n",
    "model.add(Dense(ncy,activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b491b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05e5c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train,Y_train,epochs=30,batch_size=10,validation_split=0.2,verbose=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6c2599",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ca875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921cc9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test\n",
    "y_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd831309",
   "metadata": {},
   "outputs": [],
   "source": [
    "Result = pd.DataFrame(y_hat,index=y_test.index,columns=y_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6483a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Result "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a2484d",
   "metadata": {},
   "source": [
    "The result will be the possibilty value for each substitute to have this analogous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872b3c13",
   "metadata": {},
   "source": [
    "This is the example coding material. \n",
    "\n",
    "The full research work cannot be publicied. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998d0b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model \n",
    "model.save('tfmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687be4e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
